{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c81291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "import pytz\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Check for the VIF values of the feature variables. \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Importing RFE and LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641955d8",
   "metadata": {},
   "source": [
    "### Linear Regression Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f93789f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a linear model custom funtion\n",
    "\n",
    "def lrm_vif(X_train_lm,y_train,addconstant=True):\n",
    "    \"\"\"This is a shortcut function to do linear regression model\n",
    "    with less amount of code. Here we fit a constant and use stats nmodel\n",
    "    if addconstant is given as 0 or false than we wont add the constant\"\"\"\n",
    "    \n",
    "    #This part will give us option to run statsmodel with out adding constant if needed\n",
    "    if addconstant:\n",
    "        X_train_lm = sm.add_constant(X_train_lm)\n",
    "\n",
    "        \n",
    "    lr = sm.OLS(y_train, X_train_lm).fit()\n",
    "    print('\\033[1m' +'\\n\\n LR parameters \\n' +'\\033[0m',lr.params)\n",
    "    # Check the summary\n",
    "    print('\\033[1m' +'\\n\\n\\t\\t\\t\\t LR Summary\\n\\n\\n' +'\\033[0m',lr.summary())\n",
    "    #now do the vif function call\n",
    "    checkvif(X_train_lm)\n",
    "    return lr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "103ef394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom code for VIF\n",
    "\n",
    "def checkvif(X_train_lm):\n",
    "    \"\"\"we use function for getting vif values in sorted format\"\"\"\n",
    "    vif = pd.DataFrame()\n",
    "    vif['Features'] = X_train_lm.columns\n",
    "    vif['VIF'] = [variance_inflation_factor(X_train_lm.values, i) for i in range(X_train_lm.shape[1])]\n",
    "    vif['VIF'] = round(vif['VIF'], 2)\n",
    "    vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "    print('\\033[1m' +'\\n\\n VIF Values\\n' +'\\033[0m',vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "074421d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running RFE with the output number of the variable equal to 1 by default if nothing is given\n",
    "\n",
    "def lrm_rfe(X_train,y_train,feature_count=1,addconstant=True):\n",
    "    \"\"\"we use this function for linear regression basis rfe\"\"\"\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_train, y_train)\n",
    "\n",
    "    rfe = RFE(lm, feature_count)             # running RFE\n",
    "    rfe = rfe.fit(X_train, y_train)\n",
    "    list(zip(X_train.columns,rfe.support_,rfe.ranking_))\n",
    "\n",
    "    col = X_train.columns[rfe.support_]\n",
    "    print('\\033[1m' +'columns selected are\\n' +'\\033[0m',col)\n",
    "    print('\\033[1m' +'columns rejected are\\n' +'\\033[0m',X_train.columns[~rfe.support_])\n",
    "\n",
    "    return lrm_vif(X_train[col],y_train,addconstant)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3f3cc0",
   "metadata": {},
   "source": [
    "### Logistic regression custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61c7b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_metrics(Actual,Predicted):\n",
    "    \"\"\"one function to given all confusion metrics required\"\"\"\n",
    "\n",
    "    #importing required librarires\n",
    "    from sklearn import metrics\n",
    "\n",
    "    # Confusion matrix \n",
    "    confusion = metrics.confusion_matrix(Actual,Predicted )\n",
    "    print(\"\\n confusion matrix is \\n\",confusion)\n",
    "\n",
    "\n",
    "    # Let's check the overall accuracy via function\n",
    "\n",
    "    print(\"Accuracy=\",round(metrics.accuracy_score(Actual,Predicted ),2))\n",
    "\n",
    "    #Metrics beyond simply accuracy\n",
    "    TP = confusion[1,1] # true positive \n",
    "    TN = confusion[0,0] # true negatives\n",
    "    FP = confusion[0,1] # false positives\n",
    "    FN = confusion[1,0] # false negatives\n",
    "\n",
    "\n",
    "    # Let's see the sensitivity of our logistic regression model\n",
    "    print(\"Sensitivity=\",round(TP / float(TP+FN),2))\n",
    "\n",
    "    # Let us calculate specificity\n",
    "    print(\"Specificity=\",round(TN / float(TN+FP),2))\n",
    "\n",
    "\n",
    "    # Calculate false postive rate - predicting churn when customer does not have churned\n",
    "\n",
    "\n",
    "    print(\"False postive rate=\",round(FP/ float(TN+FP),2))\n",
    "    # positive predictive value \n",
    "\n",
    "\n",
    "    print(\"Positive predictive value =\",round(TP / float(TP+FP),2))\n",
    "    # Negative predictive value\n",
    "\n",
    "    print(\"Negative predictive value=\",round(TN / float(TN+ FN),2))\n",
    "\n",
    "    #Precision\n",
    "\n",
    "    print(\"Precision using confusion matrix=\",round(confusion[1,1]/(confusion[0,1]+confusion[1,1]),2))\n",
    "\n",
    "    #recall\n",
    "\n",
    "    print(\"Recall using confusion matrix=\",round(confusion[1,1]/(confusion[1,0]+confusion[1,1]),2))\n",
    "\n",
    "    from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "    print(\"Precision using sklearn=\",round(precision_score(Actual,Predicted ),2))\n",
    "\n",
    "    print(\"Recall using sklearn=\",round(recall_score(Actual,Predicted ),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "263fdb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve for logistic regression\n",
    "def draw_roc( actual, probs ):\n",
    "    \"\"\"one function to draw the roc curve\"\"\"\n",
    "    from sklearn import metrics\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')#need to see what this does doubt\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "662b64da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestroc(y_train_pred_final):\n",
    "    \"\"\"once function to find the bestroc\"\"\"\n",
    "    \n",
    "    #importing required librarires\n",
    "    from sklearn import metrics\n",
    "    \n",
    "\n",
    "\n",
    "    # Let's create columns with different probability cutoffs \n",
    "    numbers = [float(x)/100 for x in range(100)]\n",
    "    for i in numbers:\n",
    "        y_train_pred_final[i]= y_train_pred_final['Prob'].map(lambda x: 1 if x > i else 0)\n",
    "    #y_train_pred_final.head()\n",
    "\n",
    "    # Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "    cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    # TP = confusion[1,1] # true positive \n",
    "    # TN = confusion[0,0] # true negatives\n",
    "    # FP = confusion[0,1] # false positives\n",
    "    # FN = confusion[1,0] # false negatives\n",
    "\n",
    "    \n",
    "    for i in numbers:\n",
    "        cm1 = metrics.confusion_matrix(y_train_pred_final['Actual'],y_train_pred_final[i] )\n",
    "        total1=sum(sum(cm1))\n",
    "        accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "\n",
    "        speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "        sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "        cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "    print(cutoff_df)\n",
    "\n",
    "\n",
    "    # Let's plot accuracy sensitivity and specificity for various probabilities.\n",
    "    px.line(data_frame=cutoff_df,x='prob', y=['accuracy','sensi','speci'],title='Best Probabilty curve').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95d43f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg(X_train,y_train,probaility=0.5):\n",
    "    \"\"\"This function is used to make logistic regression easy by giving all required data in once easy function\n",
    "    with all required parameters incuding roc and confusion matrix\"\"\"\n",
    "    \n",
    "    \n",
    "    X_train = sm.add_constant(X_train)\n",
    "    logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
    "    res=logm1.fit()\n",
    "    print(res.summary())\n",
    "    checkvif(X_train)\n",
    "    # Getting the predicted values on the train set\n",
    "    y_train_pred = res.predict(X_train)\n",
    "    \n",
    "    #converting to array from data frame\n",
    "    y_train_pred = y_train_pred.values.reshape(-1)\n",
    "    # Creating a dataframe with the actual churn flag and the predicted probabilities\n",
    "    y_train_pred_final = pd.DataFrame({'Actual':y_train.values, 'Prob':y_train_pred})\n",
    "    y_train_pred_final['ID'] = y_train.index\n",
    "    print(y_train_pred_final.head())\n",
    "    \n",
    "\n",
    "    #creating a new column predicted basis some probability\n",
    "    y_train_pred_final['predicted'] = y_train_pred_final.Prob.map(lambda x: 1 if x > probaility else 0)\n",
    "\n",
    "    # Let's see the head\n",
    "    y_train_pred_final.head()\n",
    "    \n",
    "    #calling the function for all metrics in one go\n",
    "\n",
    "    confusion_metrics(y_train_pred_final['Actual'],y_train_pred_final['predicted'])\n",
    "    \n",
    "    #calling function for drawing roc\n",
    "    \n",
    "    draw_roc(y_train_pred_final['Actual'],y_train_pred_final['predicted'])\n",
    "    \n",
    "    #calling function to find best roc\n",
    "    \n",
    "    bestroc(y_train_pred_final)\n",
    "    \n",
    "    \n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    p, r, thresholds = precision_recall_curve(y_train_pred_final.Actual, y_train_pred_final.Prob)\n",
    "    plt.plot(thresholds, p[:-1], \"g-\")\n",
    "    plt.plot(thresholds, r[:-1], \"r-\")\n",
    "    plt.title('Precision vs recall -precision is green and recall is red line')\n",
    "    plt.show()\n",
    "    \n",
    "    return res,X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3822572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_rfe(X_train, y_train,fcount=1):\n",
    "    \"\"\"This is used for rfe fcount means the number of features you want\"\"\"\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    logreg = LogisticRegression()\n",
    "\n",
    "    from sklearn.feature_selection import RFE\n",
    "    rfe = RFE(logreg,fcount)             # running RFE with x variables as output\n",
    "    rfe = rfe.fit(X_train, y_train)\n",
    "    print(list(zip(X_train.columns, rfe.support_, rfe.ranking_)))\n",
    "    col = X_train.columns[rfe.support_]\n",
    "    print(col)\n",
    "    return col\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97637345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbabcafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05273253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d452a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f256071",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
